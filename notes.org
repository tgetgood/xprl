* Todo list
  Thoughts about what's still missing from the language. Not sorted by priority.
  Not always actionable.
** Overloading of functions
   Right now a function has a fixed signature. Well if you're willing to call
   the destructuring bind a signature.

   At the very least we need to be able to define fns with multiple arities, but
   in general I'd like to be able to define fns with different destructuring
   patterns and use a matching algorithm to pick the correct one. You'll need to
   check them at dev time to ensure there's no ambiguity.

   The next logical step would be to add types and end up with something like
   julia's clos inspired polymorphism, but with more topology to it because the
   types can be embedded in different structures. A vector of vectors and a
   vector of maps are different in a way akin to homotopy types, but I don't
   have a good formalism yet.

   It's been my plan to implement polymorphism as a macro, but I'm a long way
   from being able to make that workable.
** Pull based channels
   Right now channels are just named continuations. They really aren't channels
   at all. At some point they will need to become proper channels which strongly
   decouple the sender from the receiver. How else is a controller to replace
   the channels going into/out of a subcomputation?

   Beyond that, I'm starting to think that the executor is backwards. It should
   be an eager operation like a print or an into which "pulls" computation out
   of a channel. By default nothing happens until something downstream demands
   an answer. This in opposition to the current behaviour where every defined
   task simply runs as soon as it has enough information to do so.

   Of course I have no idea how that is going to play along with multiple and
   optional emission. It's entirely possible that a poorly written logger could
   force everything to be eager. But seems like a possibility in any language.
   What safeguards can we have?
* Observations
** [2024-11-30 Sat] Atemporality and Messaging
   One assumption that I've been making about message passing is that if a μ
   emits messages, then we know that those message will be sent at a point in
   time strictly after μ receives its arguments.

   Not being able to assume this seems like it would make it virtually
   impossible to reason about what's going on over time.

   Te current implementation of the interpreter, however, violates this in
   certain circumstances.

   The basic assumption of the interpreter is that every time we get more
   information (a message delivered to a μ), we run the computation as far
   forward as we can with that info.

   But then what happens if we have something like:

   (μ x (μ y (emit :ch (f x))))

   where the emission doesn't depend on the value of =y= that will be sent to
   the inner μ.

   In this circumstance, (f x) will be emitted on :ch as soon as the outer μ
   receives a value for x. This means that the inner μ won't even be around to
   receive a message, which can lead to problems down the line.

   μs and emission are, in essence, a coordination language where the actual
   computations are performed by "external interpreters", or primitive functions
   which call out to ... something. In this case host language operations, but
   that won't be the case forever.

   So I think I'm going to classify the current behaviour as a bug. Eager
   interpretation is almost always the right thing to do, but not with emit, and
   likely not with other primitive macros.
** [2025-01-15 Wed 13:31] Term plans long and short
   The ultimate goal is to bootstrap the language so that it runs directly on
   hardware without dependencies. This is ludicrously ambitious, but hardly
   impossible. I've always wanted to write a compiler to verilog... but let's
   table that.

   Thus the penultimate goal is to produce a frontend on llvm. This will provide
   machine independence and decent out of the box optimisations. I say decent
   because I'm not follow what would be considered "good practice" by those who
   implement C like languages, so I expect many optimisations will be useless,
   or possibly even destructive.

   But the antepenultimate goal is to prove that all of the language constructs
   work as I expect using the interpreter written in clojure. I need a lot more
   xprl code, a lot more features (list to come later) and lots more — and more
   sophisticated — tests.

   A lot of my problems last month involved mingling these three steps. I was
   writing an interpreter that sometimes tried to compile or optimise. That made
   the interpreter hard to understand, which made getting all of the features
   right very difficult.

   A few days ago I started writing an absolutely minimal interpreter. It's 100
   lines of code and is feature complete (as an interpreter, the language is far
   from complete). This is much better base to expand upon.

   Now for the features we're still missing:

   - statefuls
     I've never been happy that these are necessary, but they are. Well I can't
     prove that, but I can't prove the opposite either, and my gut says they're
     required.
   - transduction
     I need to have a fairly complete and well tested library of transducers
     before I dive into work stealing, because I'm not sure how to go about
     ensuring streams don't get reordered when work is stolen.
   - namespaces
     More generally I need the dev time static references of xyzzy. That was the
     whole idea here to begin with and then it grew to be so much more.
   - work stealing
     There are lots of possibilities, some complicated, some slow, none
     obviously what I want.
   - bits
     I obviously can't write machine code if I can't work natively with binary
     blobs, or at least arrays of words. But really I'll need to be able to
     define C style structs and arrays and build the persistent data
     structures I want from them.
     Indeed they should be C compatible since FFI is a big part of the longer
     term plan.

   Questions:

   Do I want to bootstrap the clojure interpreter?

   That would minimise the work of porting, but it's a big endeavour. There's a
   good chance I'll start to do it just because it's interesting and then keep
   at it whether it makes sense or not. How much sense does any of this make,
   anyway?

   Do I want a compiled language?

   I like the idea of something like hotspot that interprets immediately and
   compiles behind the scenes when it finds bits that are called a lot. We could
   go much farther than java I think since we know so much more about the
   runtime dynamics (or is it just that the dynamics are simpler?).

   What are the most important debugging tools to work on?

   The prematurely optimising compiler that is no more had one advantage: When
   you viewed a μ you saw its actual innards, as opposed to the source code from
   which it is derived, but none of the local bindings. I should try and get
   that back, if only when tracing evals.

   inspection as per the julia impl would also be useful.

   What about a full blown debugger? Step up and down through the interpreter
   stages and follow messages if you wish. I'm not sure how that would work, but
   it's something I might well need.

   A better test suite. That one's a no brainer.
